{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prep_vid_v2 import get_images_tensor\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from src.model import load_model\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = [Path('data/datasets/eval')]\n",
    "models = ['adaface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in data_path:\n",
    "    for model_name in models:\n",
    "        dataset = path.parts[-1]\n",
    "        vids = list(path.rglob('*.mp4'))\n",
    "        data = {'video_id': [], 'person_id': [], 'embedding': [], 'frame_id': []}\n",
    "        model = load_model(model_name)\n",
    "        for video in tqdm(vids, desc=f'Model: {model_name}, Dataset: {dataset}'):\n",
    "            video_id = video.stem\n",
    "            person_id = video.parts[-2]\n",
    "            images = get_images_tensor(video)\n",
    "            if images is None or images.shape == torch.Size([0]):\n",
    "                data['video_id'].append(video_id)\n",
    "                data['person_id'].append(person_id)\n",
    "                data['embedding'].append(None)\n",
    "                data['frame_id'].append(None)\n",
    "                # print(f'No faces detected in {video}')\n",
    "                continue\n",
    "            embeddings = model(images.float().cuda())\n",
    "            if isinstance(embeddings, torch.Tensor):\n",
    "                embeddings = embeddings.detach().numpy()\n",
    "            for i, embedding in enumerate(embeddings):\n",
    "                embedding = embedding.squeeze()\n",
    "                data['video_id'].append(video_id)\n",
    "                data['person_id'].append(person_id)\n",
    "                data['embedding'].append(embedding)\n",
    "                data['frame_id'].append(int(i))\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_parquet(f'data/fusion_win/test.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
